{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example IRIS code \n",
    "\n",
    "This example code computes the WSS for SWORD reach 22791100061 in the same way it is computed for the ICESat-2 River Surface Slope (IRIS)dataset.  \n",
    "The method is described in detail in https://doi.org/10.1029/2022WR032842.\n",
    "\n",
    "The input data for IRIS are:\n",
    "- ATL13: ATLAS/ICESat-2 L3A Along Track Inland Surface Water Data (*Jasinski et al. 2021*)\n",
    "- SWORD: SWOT Mission River Database (*Altenau et al. 2021*).\n",
    "\n",
    "##### References\n",
    "Altenau, E. H. et al. SWOT River Database (SWORD) (Version v1), https://doi.org/10.5281/zenodo.4917236 (2021).  \n",
    "Jasinski, M. et al. ATLAS/ICESat-2 L3A Inland Water Surface Height, Version 5., https://doi.org/10.5067/ATLAS/ATL13.005 (2021).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRIS data is calculated on reach scale using functions of the custom SWORD_Reach class.  \n",
    "Objects of the SWORD_Reach class are a python representation of the SWORD reach netcdf data provided by Altenau et al. (2021).  \n",
    "Note, that all of the functions below are part of the SWORD_Reach class and are only shown for clarity and possible alternation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/DGFI15/home/scherer/.local/lib/python3.8/site-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dgfi_if import SWORD_Reach, Conversions, Utilities\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "from shapely.geometry import Polygon, LineString\n",
    "from shapely.ops import unary_union, nearest_points\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IRIS code expects the ATL13 data to be in the DGFI-TUM's internal MVA format.  \n",
    "Since the MVA database can not be shared, this example script includes a SWORD_Reach object (**r**) for SWORD reach 22791100061 which already includes all the ATL13 data extracted from the MVA database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pickle.load(open('./22791100061.pickle','rb')) # load the object for SWORD reach 22791100061"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the many SWORD_Reach functions is ***get_aoi*** which buffers the reach's centerline by its average width to construct a polygon that defines the area of interest (AOI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"18.89232531985831 45.61114267552238 0.08510402257405403 0.11117833266025201\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,91.33346368370502)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.00222356665320504\" opacity=\"0.6\" d=\"M 18.906809066402193,45.6257543383408 L 18.907449457253673,45.62603148628967 L 18.90812922270032,45.62625781070619 L 18.90884020122619,45.62643059407931 L 18.909573856261204,45.626547761739126 L 18.92713709152192,45.628648844083166 L 18.939020089015074,45.64878853382532 L 18.93929325904606,45.649196272292485 L 18.93961953487472,45.64958433454347 L 18.93999606507094,45.64994932788532 L 18.94041955865952,45.65028806124144 L 18.940886313871523,45.6505975730631 L 18.95528893854694,45.65928846469706 L 18.95817288903343,45.662595761729364 L 18.959453124748276,45.66687824595055 L 18.958294212902917,45.671900941346756 L 18.955524248752017,45.67371818288278 L 18.93260712582718,45.681780345769624 L 18.93180017920799,45.68211417870851 L 18.916973368365973,45.68924349593351 L 18.916455617167525,45.689518464923154 L 18.915977201750955,45.68982645206961 L 18.915542393197597,45.69016470820758 L 18.915155073552178,45.690530213937244 L 18.90192397946877,45.70432939731931 L 18.901609102507397,45.70469108236927 L 18.901340783664203,45.70507074814834 L 18.90112109804183,45.70546545976876 L 18.89644303588276,45.71510040683475 L 18.90946725753764,45.71820329215818 L 18.913849633275216,45.709173172170175 L 18.925836862852528,45.69666874514611 L 18.93919277512803,45.69024624196038 L 18.96258036300774,45.68201813806513 L 18.963152983685372,45.68179194291388 L 18.963692161675255,45.6815284453492 L 18.964192967035682,45.6812300548609 L 18.969401745306392,45.67781240981957 L 18.969852113604563,45.67748772657279 L 18.97025700383128,45.67713483675592 L 18.97061283975035,45.67675685805155 L 18.970916478700723,45.67635712973521 L 18.971165239337395,45.67593918316159 L 18.971356925288706,45.67550671055582 L 18.97148984452209,45.67506353238553 L 18.97322549483557,45.66753351831258 L 18.97329739870639,45.66709446873079 L 18.97331162640791,45.666652646844575 L 18.973268059615638,45.66621176925826 L 18.973167066160713,45.6657755445462 L 18.97138019847666,45.659803155761644 L 18.97117592097257,45.659272827254064 L 18.97088689467101,45.658762248538736 L 18.97051687804183,45.65827805511636 L 18.96644988109565,45.65361518945322 L 18.966046646188282,45.653202587441825 L 18.96558459671888,45.65282152377023 L 18.965068712375427,45.65247610434127 L 18.95108869109341,45.644041387069414 L 18.93837640498305,45.62250309944574 L 18.938079343517337,45.62206373930996 L 18.937720687555704,45.621647626098174 L 18.937304091113855,45.62125899764454 L 18.93683379803328,45.62090181178056 L 18.936314598732935,45.6205797060462 L 18.935751781408275,45.620295960664684 L 18.935151078174815,45.620053465156765 L 18.934518606704685,45.619854688933714 L 18.93386080794956,45.61970165616752 L 18.93318438058307,45.61959592519325 L 18.91339159148372,45.61722866992011 L 18.909356634282727,45.61526039154683 L 18.901517461814574,45.62317292416845 L 18.906809066402193,45.6257543383408 z\" /></g></svg>",
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x7fbaf1893760>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_aoi(self,buffersize=None, std_multiplicator = 1):\n",
    "    \"\"\" get a coarse aoi of the reach buffered by the given parameter or the width plus four times the width standard deviation\"\"\"\n",
    "    if buffersize is None:\n",
    "        buffersize = self.width + std_multiplicator * self.width_std\n",
    "       \n",
    "    centerline_wgs84 = LineString(self.coords[1:-1])\n",
    "    epsg_utm = Conversions.convert_wgs_to_utm_zone(geometry=centerline_wgs84)\n",
    "    centerline_utm = Conversions.convert_wgs_geometry_to_utm(centerline_wgs84,epsg_utm)\n",
    "\n",
    "    centerline_utm = centerline_utm.simplify(tolerance=100)\n",
    "    aoi_utm = centerline_utm.buffer(buffersize, cap_style=2)\n",
    "    aoi_wgs84 = Conversions.convert_utm_geometry_to_wgs(aoi_utm, epsg_utm)\n",
    "    if aoi_wgs84.geom_type != 'Polygon':\n",
    "        aoi_wgs84 = aoi_wgs84.convex_hull\n",
    "    return list(aoi_wgs84.exterior.coords)\n",
    "r.aoi = get_aoi(r, std_multiplicator=0) # For IRIS v1 the std_multiplicator is set to 0\n",
    "Polygon(r.aoi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ATL13 data from MVA is stored in the attribute *features_by_mission*.  \n",
    "Each feature contains parts of the ATL13 data from a specific beam and day intersecting the reach AOI stored as a pandas DataFrame.  \n",
    "Below, the ATL13 data of the first feature is shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>wgs_coord</th>\n",
       "      <th>alongtrack_distance</th>\n",
       "      <th>elev</th>\n",
       "      <th>depth</th>\n",
       "      <th>atl13_slope</th>\n",
       "      <th>jday</th>\n",
       "      <th>strong</th>\n",
       "      <th>geoh07</th>\n",
       "      <th>water_body_id</th>\n",
       "      <th>water_body_type</th>\n",
       "      <th>cloud_flag_asr_atl09</th>\n",
       "      <th>cloud_flag_atm_atl09</th>\n",
       "      <th>layer_flag_atl09</th>\n",
       "      <th>qf_cloud</th>\n",
       "      <th>qf_ice</th>\n",
       "      <th>snow_ice_atl09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.941152</td>\n",
       "      <td>45.631690</td>\n",
       "      <td>(18.941152, 45.63169)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.902</td>\n",
       "      <td>11.125</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6993.82575</td>\n",
       "      <td>None</td>\n",
       "      <td>44.807</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.941118</td>\n",
       "      <td>45.631931</td>\n",
       "      <td>(18.941118, 45.631930999999994)</td>\n",
       "      <td>26.958228</td>\n",
       "      <td>124.910</td>\n",
       "      <td>11.125</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6993.82575</td>\n",
       "      <td>None</td>\n",
       "      <td>44.807</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.941083</td>\n",
       "      <td>45.632184</td>\n",
       "      <td>(18.941083, 45.632183999999995)</td>\n",
       "      <td>55.253504</td>\n",
       "      <td>124.885</td>\n",
       "      <td>11.125</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6993.82575</td>\n",
       "      <td>None</td>\n",
       "      <td>44.807</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.941068</td>\n",
       "      <td>45.632292</td>\n",
       "      <td>(18.941067999999998, 45.632292)</td>\n",
       "      <td>67.332574</td>\n",
       "      <td>124.844</td>\n",
       "      <td>11.125</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6993.82575</td>\n",
       "      <td>None</td>\n",
       "      <td>44.807</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.941061</td>\n",
       "      <td>45.632349</td>\n",
       "      <td>(18.941060999999998, 45.632349)</td>\n",
       "      <td>73.700747</td>\n",
       "      <td>124.816</td>\n",
       "      <td>11.125</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>6993.82575</td>\n",
       "      <td>None</td>\n",
       "      <td>44.807</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>18.932704</td>\n",
       "      <td>45.692577</td>\n",
       "      <td>(18.932703999999998, 45.692577)</td>\n",
       "      <td>6809.702158</td>\n",
       "      <td>125.127</td>\n",
       "      <td>14.995</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>6993.82576</td>\n",
       "      <td>None</td>\n",
       "      <td>44.772</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>18.932696</td>\n",
       "      <td>45.692634</td>\n",
       "      <td>(18.932696, 45.692634)</td>\n",
       "      <td>6816.077786</td>\n",
       "      <td>125.133</td>\n",
       "      <td>14.995</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>6993.82576</td>\n",
       "      <td>None</td>\n",
       "      <td>44.772</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>18.932688</td>\n",
       "      <td>45.692698</td>\n",
       "      <td>(18.932688, 45.692698)</td>\n",
       "      <td>6823.229007</td>\n",
       "      <td>125.149</td>\n",
       "      <td>14.995</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>6993.82576</td>\n",
       "      <td>None</td>\n",
       "      <td>44.772</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>18.932681</td>\n",
       "      <td>45.692749</td>\n",
       "      <td>(18.932681, 45.692749)</td>\n",
       "      <td>6828.932330</td>\n",
       "      <td>125.168</td>\n",
       "      <td>14.995</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>6993.82576</td>\n",
       "      <td>None</td>\n",
       "      <td>44.772</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>18.932667</td>\n",
       "      <td>45.692858</td>\n",
       "      <td>(18.932667, 45.692858)</td>\n",
       "      <td>6841.114571</td>\n",
       "      <td>125.189</td>\n",
       "      <td>14.995</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>6993.82576</td>\n",
       "      <td>None</td>\n",
       "      <td>44.772</td>\n",
       "      <td>2006069</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lon        lat                        wgs_coord  \\\n",
       "0    18.941152  45.631690            (18.941152, 45.63169)   \n",
       "1    18.941118  45.631931  (18.941118, 45.631930999999994)   \n",
       "2    18.941083  45.632184  (18.941083, 45.632183999999995)   \n",
       "3    18.941068  45.632292  (18.941067999999998, 45.632292)   \n",
       "4    18.941061  45.632349  (18.941060999999998, 45.632349)   \n",
       "..         ...        ...                              ...   \n",
       "465  18.932704  45.692577  (18.932703999999998, 45.692577)   \n",
       "466  18.932696  45.692634           (18.932696, 45.692634)   \n",
       "467  18.932688  45.692698           (18.932688, 45.692698)   \n",
       "468  18.932681  45.692749           (18.932681, 45.692749)   \n",
       "469  18.932667  45.692858           (18.932667, 45.692858)   \n",
       "\n",
       "     alongtrack_distance     elev   depth  atl13_slope        jday strong  \\\n",
       "0               0.000000  124.902  11.125    -0.000031  6993.82575   None   \n",
       "1              26.958228  124.910  11.125    -0.000031  6993.82575   None   \n",
       "2              55.253504  124.885  11.125    -0.000031  6993.82575   None   \n",
       "3              67.332574  124.844  11.125    -0.000031  6993.82575   None   \n",
       "4              73.700747  124.816  11.125    -0.000031  6993.82575   None   \n",
       "..                   ...      ...     ...          ...         ...    ...   \n",
       "465          6809.702158  125.127  14.995     0.000660  6993.82576   None   \n",
       "466          6816.077786  125.133  14.995     0.000660  6993.82576   None   \n",
       "467          6823.229007  125.149  14.995     0.000660  6993.82576   None   \n",
       "468          6828.932330  125.168  14.995     0.000660  6993.82576   None   \n",
       "469          6841.114571  125.189  14.995     0.000660  6993.82576   None   \n",
       "\n",
       "     geoh07  water_body_id  water_body_type  cloud_flag_asr_atl09  \\\n",
       "0    44.807        2006069                5                     2   \n",
       "1    44.807        2006069                5                     2   \n",
       "2    44.807        2006069                5                     2   \n",
       "3    44.807        2006069                5                     2   \n",
       "4    44.807        2006069                5                     2   \n",
       "..      ...            ...              ...                   ...   \n",
       "465  44.772        2006069                5                     1   \n",
       "466  44.772        2006069                5                     1   \n",
       "467  44.772        2006069                5                     1   \n",
       "468  44.772        2006069                5                     1   \n",
       "469  44.772        2006069                5                     1   \n",
       "\n",
       "     cloud_flag_atm_atl09  layer_flag_atl09  qf_cloud  qf_ice  snow_ice_atl09  \n",
       "0                       1                 0       NaN     NaN               1  \n",
       "1                       1                 0       NaN     NaN               1  \n",
       "2                       1                 0       NaN     NaN               1  \n",
       "3                       1                 0       NaN     NaN               1  \n",
       "4                       1                 0       NaN     NaN               1  \n",
       "..                    ...               ...       ...     ...             ...  \n",
       "465                     1                 0       NaN     NaN               1  \n",
       "466                     1                 0       NaN     NaN               1  \n",
       "467                     1                 0       NaN     NaN               1  \n",
       "468                     1                 0       NaN     NaN               1  \n",
       "469                     1                 0       NaN     NaN               1  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.features_by_mission['icesat2_gt1l_atl13v5_hf'][0]['data']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we iterate over all features and apply the function *icesat2_pass_helper*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icesat2_pass_helper(self, feature : Dict, max_median_deviation : float = 0.05, min_size_to_apply_window : int = 20, window_size : int = 7, max_slope : float = 0.0003, debug : Union[bool,str]= False):\n",
    "    \"\"\"Helper Function to reject outliers and convert along track slope to along centerline slope\"\"\"\n",
    "    pass_geom = wkt.loads(feature['geometry'])\n",
    "    centerline = LineString(self.coords)\n",
    "\n",
    "    #######################################################################################\n",
    "    ### First Intersection for splitting features if necessary\n",
    "    intersection = pass_geom.intersection(centerline)\n",
    "    if intersection.is_empty:\n",
    "        nearest = nearest_points(pass_geom, centerline)\n",
    "        ref_point_lon = nearest[0].x\n",
    "        ref_point_lat = nearest[0].y\n",
    "    elif intersection.geom_type == 'Point':\n",
    "        ref_point_lon = intersection.x\n",
    "        ref_point_lat = intersection.y\n",
    "    elif intersection.geom_type == 'MultiPoint':\n",
    "        distances = {}\n",
    "        for i, point in enumerate(intersection.geoms):\n",
    "            distances[i] = feature['data'].apply(lambda x: Utilities.openadb_spherical_distance(point.x,point.y,x.lon,x.lat),axis=1)\n",
    "        df = pd.DataFrame(distances)\n",
    "        nearest_point = df.idxmin(axis=1)\n",
    "        data = []\n",
    "        for i in distances.keys():\n",
    "            this_index = nearest_point[nearest_point == i]\n",
    "            new_feature = deepcopy(feature)\n",
    "            new_feature['data'] = new_feature['data'][new_feature['data'].index.isin(this_index.index)]\n",
    "            if len(new_feature['data'].lon) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                new_feature['geometry'] = Utilities.linestring_helper(new_feature['data'].lon, new_feature['data'].lat)\n",
    "                _data = self.icesat2_pass_helper(feature=new_feature,max_median_deviation=max_median_deviation,min_size_to_apply_window=min_size_to_apply_window,window_size=window_size,debug=debug)\n",
    "            except Utilities.MiscException as e:\n",
    "                _data = None\n",
    "            except SWORDException as e:\n",
    "                _data = None\n",
    "            if _data is not None:\n",
    "                data.append(_data)\n",
    "        return data\n",
    "    #######################################################################################\n",
    "\n",
    "    atl13_pass_data = feature['data']\n",
    "    epsg_utm = Utilities.convert_wgs_to_utm_zone(lon=ref_point_lon, lat=ref_point_lat)\n",
    "    ydata = atl13_pass_data.elev - atl13_pass_data.geoh07\n",
    "    xdata = atl13_pass_data.alongtrack_distance\n",
    "\n",
    "    #######################################################################################\n",
    "    ### Outlier Detection\n",
    "\n",
    "    if ydata.shape[0] > min_size_to_apply_window:\n",
    "        window_median = ydata.rolling(window_size,min_periods=int(np.floor(window_size/2)),center=True).median()\n",
    "        median_flags = (window_median - ydata).abs() <= max_median_deviation # False : AMD Outlier\n",
    "    else:\n",
    "        median_flags = (ydata - ydata.median()) <= max_median_deviation # False : AMD Outlier\n",
    "    \n",
    "    type_flags = True #atl13_pass_data.water_body_type.isin([2,5,6]) # Allowed Values: Reservoir, River, Estuary -> False : Type Outlier\n",
    "    cloud_flags = atl13_pass_data.cloud_flag_asr_atl09.isin([0,1,2,3]) # -> False: Cloud Outlier\n",
    "    ice_flags = atl13_pass_data.snow_ice_atl09.isin([0,1]) # -> False: Ice Outlier\n",
    "    flags = type_flags & median_flags & cloud_flags & ice_flags # False : Type, Cloud, Ice, and AMD Outlier\n",
    "    \n",
    "    atl13_pass_data.loc[:,\"type_flag\"] = type_flags\n",
    "    atl13_pass_data.loc[:,\"median_flag\"] = median_flags\n",
    "    atl13_pass_data.loc[:,\"cloud_flag\"] = cloud_flags\n",
    "    atl13_pass_data.loc[:,\"ice_flags\"] = ice_flags\n",
    "    \n",
    "    xdata_ice_outlier = xdata.loc[~ice_flags]\n",
    "    ydata_ice_outlier = ydata.loc[~ice_flags]\n",
    "\n",
    "    amd_xdata_outlier = xdata.loc[~flags] # For Debug Plot\n",
    "    amd_ydata_outlier = ydata.loc[~flags] # For Debug Plot\n",
    "    xdata = xdata.loc[flags]\n",
    "    ydata = ydata.loc[flags]\n",
    "    \n",
    "    if xdata.shape[0] < 2:\n",
    "        logger.debug('No Data after AMD and Type Outlier removal')\n",
    "        return None\n",
    "    \n",
    "    clusters = (xdata.diff() > 500).cumsum()\n",
    "    cluster_flags = clusters == clusters.value_counts().idxmax() # False: Cluster Outlier (Only longest Cluster is used)\n",
    "\n",
    "    cluster_xdata_outlier = xdata.loc[~cluster_flags] # For Debug Plot\n",
    "    cluster_ydata_outlier = ydata.loc[~cluster_flags] # For Debug Plot\n",
    "    xdata = xdata.loc[cluster_flags]\n",
    "    ydata = ydata.loc[cluster_flags]\n",
    "\n",
    "    atl13_pass_data.loc[:,\"cluster_flag\"] = atl13_pass_data.index.isin(xdata.index) #cluster_flags\n",
    "\n",
    "    if xdata.shape[0] < 2:\n",
    "        logger.debug('No Data after Cluster Outlier removal')\n",
    "        return None\n",
    "\n",
    "    #######################################################################################\n",
    "    ###  Position and Angle Determination\n",
    "    pass_geom = Utilities.validate_geometry(LineString(atl13_pass_data[atl13_pass_data.cluster_flag.fillna(False)].wgs_coord.to_list()))\n",
    "    intersection = pass_geom.intersection(centerline)\n",
    "    if intersection.is_empty:\n",
    "        nearest = nearest_points(pass_geom, centerline)\n",
    "        ref_point_lon = nearest[0].x\n",
    "        ref_point_lat = nearest[0].y\n",
    "    elif intersection.geom_type == 'Point':\n",
    "        ref_point_lon = intersection.x\n",
    "        ref_point_lat = intersection.y\n",
    "    elif intersection.geom_type == 'MultiPoint':\n",
    "        raise SWORDException('Feature should be split')\n",
    "    atl13_pass_data.loc[:,'ref_distance'] = Utilities.great_circle_dist(atl13_pass_data.lon.to_numpy(), atl13_pass_data.lat.to_numpy(), ref_point_lon, ref_point_lat) * 1000\n",
    "    x0 = atl13_pass_data.alongtrack_distance.loc[atl13_pass_data.ref_distance.idxmin()]\n",
    "    postion = self.get_reach_position_of_closest_cl_point(ref_point_lon, ref_point_lat)\n",
    "    node_id = self.search_reach_id(lon=ref_point_lon, lat=ref_point_lat, return_node=True)\n",
    "    normal = self.get_node_normal(node_id, pointing='straight')\n",
    "    normal_utm = Utilities.convert_wgs_geometry_to_utm(normal, epsg_utm)\n",
    "    normal_coords = np.asarray(Utilities.get_geom_coordinates(normal_utm))\n",
    "    pass_geom_utm = Utilities.convert_wgs_geometry_to_utm(pass_geom, epsg_utm)\n",
    "    pass_coords = np.asarray(Utilities.get_geom_coordinates(pass_geom_utm))\n",
    "    \n",
    "    normal_vector = normal_coords[-1] - normal_coords[0]\n",
    "    pass_vector = pass_coords[-1] - pass_coords[0]\n",
    "    u, v = pass_vector, normal_vector\n",
    "    u_norm = np.sqrt(sum(u*u))\n",
    "    v_norm = np.sqrt(sum(v*v))\n",
    "    dot = np.dot(u, v)\n",
    "\n",
    "    #######################################################################################\n",
    "    ### This Block handles pass height estmate using SVR based on DAHITI approach and SVR outlier rejection\n",
    "    limit = ((xdata.max() - xdata.min()) * max_slope) / 2\n",
    "    limit = .05\n",
    "    distances = np.abs(xdata - x0)\n",
    "    distance_weights = 1./np.where(distances==0,1,distances)\n",
    "    xscaler = StandardScaler() # SVR works better when data is scaled\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler.fit(xdata.to_numpy().reshape(-1, 1))\n",
    "    yscaler.fit(ydata.to_numpy().reshape(-1, 1))\n",
    "    xscaled = xscaler.transform(xdata.to_numpy().reshape(-1, 1))\n",
    "    yscaled = yscaler.transform(ydata.to_numpy().reshape(-1, 1))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(action='ignore',message='Liblinear failed to converge, increase the number of iterations.')\n",
    "        svr = LinearSVR(random_state=0,max_iter=1e6)\n",
    "        svr.fit(xscaled,np.ravel(yscaled),sample_weight=distance_weights)\n",
    "    y_predict = yscaler.inverse_transform(svr.predict(xscaled))\n",
    "    y_deviation = (ydata - y_predict).abs()\n",
    "    svr_flags = y_deviation <= limit\n",
    "    y_predict = y_predict[svr_flags]\n",
    "    if y_predict.size > 0:\n",
    "        # svr_elev = np.nanmean(y_predict)\n",
    "        # distances = distances[svr_flags]\n",
    "        svr_elev = np.average(ydata[svr_flags],weights=distance_weights[svr_flags])\n",
    "        median_elev = np.median(ydata)\n",
    "    else:\n",
    "        svr_elev = np.nan\n",
    "        median_elev = np.nan\n",
    "\n",
    "    svr_xdata_outlier = xdata.loc[~svr_flags] # For Debug Plot\n",
    "    svr_ydata_outlier = ydata.loc[~svr_flags] # For Debug Plot\n",
    "    xdata = xdata[svr_flags]\n",
    "    ydata = ydata[svr_flags]\n",
    "    width = np.max(xdata) - np.min(xdata)\n",
    "    atl13_pass_data.loc[:,'svr_flag'] = atl13_pass_data.index.isin(xdata.index)\n",
    "    atl13_pass_data.loc[:,'rejected'] = ~(atl13_pass_data.svr_flag & atl13_pass_data.cluster_flag & atl13_pass_data.median_flag & atl13_pass_data.type_flag)\n",
    "\n",
    "    if xdata.shape[0] < 2:\n",
    "        if debug:\n",
    "            logger.debug('No Data after SVR Outlier removal')\n",
    "        return None\n",
    "\n",
    "    #######################################################################################\n",
    "    ### This Block handles the conversion from atl13 along track slope to along river centerline slope\n",
    "    dot_crossing_angle_deg = np.rad2deg(np.arccos(dot/(u_norm * v_norm)))\n",
    "    if dot != 0 and xdata.size > 1: # orthogonal flying\n",
    "        tinv = lambda p, df: abs(stats.t.ppf(p/2, df))\n",
    "        ts = tinv(0.05, len(xdata)-2)\n",
    "        slope, intercept, r, p, se = stats.linregress(xdata, ydata)\n",
    "        slope_confidence = ts*se \n",
    "        dh = -1 * (u_norm * slope)\n",
    "        proj_of_u_on_v = (dot/v_norm**2)*v\n",
    "        l = np.sqrt(sum(proj_of_u_on_v**2))\n",
    "        adjusted_custom_along_track_slope = (dh/l) * np.sign(dot)\n",
    "    else:\n",
    "        adjusted_custom_along_track_slope = np.nan\n",
    "        slope, intercept, r, p, se = np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "        slope_confidence = np.nan\n",
    "    \n",
    "    #######################################################################################\n",
    "\n",
    "    date_object = julianDayDate(np.nanmean(atl13_pass_data.jday))\n",
    "    date = datetime.datetime(year=date_object[\"year\"], month=date_object[\"month\"], day=date_object[\"day\"], hour=date_object[\"hour\"], minute=date_object[\"minute\"])\n",
    "\n",
    "    if debug is True or debug == date.strftime('%Y-%m-%d'):\n",
    "        plt.rc('font', size=14)  \n",
    "        fig, ax = plt.subplots(figsize=(20,10))\n",
    "        plt.sca(ax)\n",
    "        cloud_flag_asr_atl09 = atl13_pass_data[atl13_pass_data.svr_flag].cloud_flag_asr_atl09.to_numpy()\n",
    "        sc = plt.scatter(xdata, ydata, c=cloud_flag_asr_atl09, label='Valid ATL13 Observations', cmap=matplotlib.colors.ListedColormap([tum.blue,tum.light_blue2,tum.light_blue,tum.light_grey,tum.dark_grey,tum.orange]), vmax=6)\n",
    "        ylim = list(plt.ylim())\n",
    "        xlim = list(plt.xlim())\n",
    "        plt.plot(amd_xdata_outlier, amd_ydata_outlier, '.',color=tum.grey, label='Type, Cloud, or AMD Outlier')\n",
    "        plt.plot(svr_xdata_outlier, svr_ydata_outlier, '+',color=tum.grey, label='SVR Outlier')\n",
    "        plt.plot(cluster_xdata_outlier, cluster_ydata_outlier, 'x',color=tum.grey, label='Cluster Outlier')\n",
    "        plt.plot(xdata_ice_outlier, ydata_ice_outlier, '.',color='red', label='ICE Outlier')\n",
    "        # plt.colorbar(sc)\n",
    "        plt.plot(xdata, intercept + slope*xdata, color=tum.orange, label='Slope Fit')\n",
    "        # plt.plot(xdata,y_predict,'b--',label=\"SVR fit\")\n",
    "        if svr_elev is not None:\n",
    "            plt.axhline(svr_elev, label='Reference Point/Elevation',color=tum.grey)\n",
    "        else:\n",
    "            plt.axhline(median_elev, label='Median Height', linestyle='--')\n",
    "        plt.axvline(x0,color=tum.grey)\n",
    "        plt.xlabel('Along Track Distance [m]')\n",
    "        plt.ylabel('Elevation [m]')\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "        plt.title(f'Reach {self.reach_id} Date {date_str} Beam {feature[\"beam\"]}\\nCrossing Angle: {dot_crossing_angle_deg:.2f} Along Track Slope: {adjusted_custom_along_track_slope*1e6:.0f} +- {slope_confidence*1e6:.0f} mm/km')\n",
    "        quantiles = (atl13_pass_data.elev - atl13_pass_data.geoh07).quantile([0.1,0.99]).to_list()\n",
    "        if ylim[0] > quantiles[0]:\n",
    "            ylim[0] = quantiles[0]\n",
    "        if ylim[1] < quantiles[1]:\n",
    "            ylim[1] = quantiles[1]\n",
    "        plt.ylim(ylim)\n",
    "        # plt.xlim(xlim)\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        _df = gpd.GeoDataFrame(atl13_pass_data,geometry=atl13_pass_data.wgs_coord.apply(Point))\n",
    "        _df = _df.set_crs(epsg=4326)\n",
    "        _df = _df.to_crs(epsg=3857)\n",
    "        _centerline = gpd.GeoSeries(centerline)\n",
    "        _centerline = _centerline.set_crs(epsg=4326)\n",
    "        _centerline = _centerline.to_crs(epsg=3857)\n",
    "        ax = _df[~_df.rejected].plot(figsize=(6, 6),color=tum.light_blue2, label=\"Valid ATL13 Observations\")\n",
    "        _centerline.plot(ax=ax,linewidth=2, label=\"centerline\",color=tum.orange)\n",
    "\n",
    "        _aoi = gpd.GeoSeries(Polygon(self.aoi))\n",
    "        _aoi = _aoi.set_crs(epsg=4326)\n",
    "        _aoi = _aoi.to_crs(epsg=3857)\n",
    "        _aoi.plot(ax=ax,linewidth=2, label=\"centerline\",color=tum.blue,alpha=0.5)\n",
    "\n",
    "        # ax.axis('equal')\n",
    "        ymin, ymax = plt.ylim()\n",
    "        xmin, xmax = plt.xlim()\n",
    "        xamp = xmax - xmin\n",
    "        yamp = ymax - ymin\n",
    "        buffer = np.abs((xamp - yamp) / 2.)\n",
    "        if xamp > yamp:\n",
    "            ymax += buffer\n",
    "            ymin -= buffer\n",
    "        else:\n",
    "            xmax += buffer\n",
    "            xmin -= buffer\n",
    "\n",
    "        bounds = gpd.GeoSeries(box(xmin,ymin,xmax,ymax)).set_crs(3857)\n",
    "        bounds.plot(ax=ax,facecolor=\"none\",edgecolor=\"none\")\n",
    "        bounds = bounds.to_crs(4326).iloc[0]\n",
    "        # plt.ylim(np.array(plt.ylim()) + np.array([-1e4,1e4]))\n",
    "        # plt.xlim(np.array(plt.xlim()) + np.array([-1e4,1e4]))\n",
    "        try:\n",
    "            # cx.add_basemap(ax, crs=_df.crs, source=cx.providers.Esri.WorldImagery)\n",
    "            from .import EE_IF\n",
    "            ee = EE_IF()\n",
    "            url = ee.get_s2_mosaic_url(date=date,poi=bounds,daysdelta=21)\n",
    "            cx.add_basemap(ax, crs=_df.crs, source=url)\n",
    "        except:\n",
    "            ...\n",
    "        ax.add_artist(ScaleBar(2,location=\"lower right\"))\n",
    "        plt.legend()\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "            \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(action='ignore')\n",
    "        return {\n",
    "            'date': date.date(),\n",
    "            'timestamp': date,\n",
    "            'mission': feature['mission'],\n",
    "            'position': postion,\n",
    "            'lon': ref_point_lon,\n",
    "            'lat': ref_point_lat,\n",
    "            'median_elev': median_elev,\n",
    "            'svr_elev' : svr_elev,\n",
    "            'elev' : svr_elev if svr_elev is not None else median_elev,\n",
    "            'elev_std': atl13_pass_data.elev[~atl13_pass_data.rejected].std(),\n",
    "            'atl13_slope': atl13_pass_data.atl13_slope[~atl13_pass_data.rejected].median(),\n",
    "            'min_depth': atl13_pass_data.depth[~atl13_pass_data.rejected].min(),\n",
    "            'max_depth': atl13_pass_data.depth[~atl13_pass_data.rejected].max(),\n",
    "            'median_depth': atl13_pass_data.depth[~atl13_pass_data.rejected].median(),\n",
    "            'water_body_ids' : atl13_pass_data.water_body_id[~atl13_pass_data.rejected].unique(),\n",
    "            'water_body_types' : atl13_pass_data.water_body_type[~atl13_pass_data.rejected].unique(),\n",
    "            'hf_data': atl13_pass_data,\n",
    "            'custom_along_track_slope' : slope,\n",
    "            'custom_along_track_slope_err': se,\n",
    "            'custom_along_track_slope_abs_rvalue': np.abs(r),\n",
    "            'custom_along_track_slope_pvalue': p,\n",
    "            'adjusted_custom_along_track_slope' : adjusted_custom_along_track_slope,\n",
    "            'dot_crossing_angle_deg' : dot_crossing_angle_deg,\n",
    "            'node_id' : node_id,\n",
    "            'width' : width,\n",
    "            'slope_confidence': slope_confidence,\n",
    "            }\n",
    "\n",
    "icesat2_data = []\n",
    "def rec_append(input):\n",
    "    # Helper Function for nested data\n",
    "    if isinstance(input,list):\n",
    "        for item in input:\n",
    "            rec_append(item)\n",
    "    else:\n",
    "        icesat2_data.append(input)\n",
    "\n",
    "for features in tqdm(list(r.features_by_mission.values()), desc=f'Estimating ICESat-2 Heights and Along Slope for Reach {r.reach_id} by beam', leave=False):\n",
    "    for feature in features:\n",
    "        if feature['data'].empty:\n",
    "            continue\n",
    "        data = r.icesat2_pass_helper(feature)\n",
    "        if data is None:\n",
    "            continue\n",
    "        if isinstance(data, list):\n",
    "            rec_append(data)\n",
    "        else:\n",
    "            icesat2_data.append(data)\n",
    "r.icesat2_data = pd.DataFrame(icesat2_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
